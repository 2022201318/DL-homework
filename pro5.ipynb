{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载论文数据...\n",
      "共加载 10526 篇论文。\n",
      "并行处理论文数据...\n",
      "Introduction扩展任务失败 paper-710: cannot access local variable 'response' where it is not associated with a value\n",
      "Introduction扩展任务失败 paper-4089: cannot access local variable 'response' where it is not associated with a value\n",
      "更新论文数据...\n",
      "保存处理后的数据...\n",
      "处理完成，已保存到 papers_with_intro.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import concurrent.futures\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# 初始化 ZhipuAI 客户端\n",
    "client = ZhipuAI(api_key=\"ad670367ab3640d78468ddc62b7ca3f2.GhKvhDzmSOe3QN9O\")\n",
    "\n",
    "# 定义“Introduction”扩展任务描述模板\n",
    "task_description_template_intro = \"\"\"\n",
    "请根据以下论文摘要，扩展出一个简短的“Introduction”部分，介绍论文的背景、研究问题、方法和主要贡献。\n",
    "\n",
    "论文摘要: {abstract}\n",
    "\n",
    "输出格式：\n",
    "{{\n",
    "    \"Introduction\": \"扩展出的Introduction内容\"\n",
    "}}\n",
    "请确保生成的Introduction简洁明了，能够准确概括论文的背景、研究问题、方法和贡献。\n",
    "你回答的Introduction必须是英文，而且你的回答中不应该包含除可解析的json外的注释等任何内容\n",
    "\"\"\"\n",
    "\n",
    "# 加载论文数据\n",
    "def load_papers(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 保存处理后的论文数据\n",
    "def save_papers(papers, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 记录模型的回复日志\n",
    "def log_model_response(idx, response_text):\n",
    "    with open(\"model_response_log_intro.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"Paper-{idx} Response: {response_text}\\n\\n\")\n",
    "\n",
    "# 记录错误日志\n",
    "def log_error(idx, error_message, model_response=None):\n",
    "    with open(\"error_log_intro.txt\", \"a\", encoding=\"utf-8\") as error_file:\n",
    "        error_file.write(f\"Error for Paper-{idx}: {error_message}\\n\")\n",
    "        if model_response:\n",
    "            error_file.write(f\"Model Response: {model_response}\\n\\n\")\n",
    "\n",
    "# 清洗模型返回的内容，提取最外层大括号中的内容\n",
    "def extract_outer_braces_content(response_text):\n",
    "    # 使用正则提取最外层的括号内的内容\n",
    "    match = re.search(r\"^\\{(.*)\\}$\", response_text.strip(), re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()  # 返回大括号内的内容\n",
    "    else:\n",
    "        return response_text.strip()  # 如果无法匹配，返回原始内容\n",
    "\n",
    "# 发送请求并解析“Introduction”扩展内容\n",
    "def process_paper_intro(paper, idx):\n",
    "    abstract = paper.get('abstract', \"\")\n",
    "    task_description = task_description_template_intro.format(abstract=abstract)\n",
    "\n",
    "    try:\n",
    "        # 调用大模型 API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"glm-4-flash\",  # 使用 glm-4-flash 模型\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个生成论文Introduction部分的助手。\"},\n",
    "                {\"role\": \"user\", \"content\": task_description}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "        # 提取回复内容\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # 记录模型回复日志\n",
    "        log_model_response(idx, response_text)\n",
    "\n",
    "        # 提取最外层大括号中的内容\n",
    "        extracted_content = extract_outer_braces_content(response_text)\n",
    "\n",
    "        # 返回处理后的内容\n",
    "        return {\n",
    "            \"Introduction\": extracted_content\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # 记录错误日志，且记录模型原始返回内容\n",
    "        log_error(idx, str(e), model_response=response.choices[0].message.content.strip())\n",
    "        print(f\"解析失败: {e} for paper-{idx}\")\n",
    "\n",
    "        # 返回大模型返回的原始内容\n",
    "        return {\n",
    "            \"Introduction\": f\"模型返回原始内容: {response.choices[0].message.content.strip()}\"\n",
    "        }\n",
    "\n",
    "# 并行处理论文数据\n",
    "def process_papers_concurrently(papers, max_workers=5):\n",
    "    results_intro = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures_intro = {executor.submit(process_paper_intro, paper, idx): idx for idx, paper in enumerate(papers, 1)}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures_intro):\n",
    "            idx = futures_intro[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results_intro.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Introduction扩展任务失败 paper-{idx}: {e}\")\n",
    "                results_intro.append({\"Introduction\": \"\"})\n",
    "\n",
    "    return results_intro\n",
    "\n",
    "# 主函数\n",
    "def main(input_json, output_json, max_workers=5):\n",
    "    print(\"加载论文数据...\")\n",
    "    papers = load_papers(input_json)\n",
    "    print(f\"共加载 {len(papers)} 篇论文。\")\n",
    "\n",
    "    print(\"并行处理论文数据...\")\n",
    "    extended_intros = process_papers_concurrently(papers, max_workers=max_workers)\n",
    "\n",
    "    print(\"更新论文数据...\")\n",
    "    for paper, result_intro in zip(papers, extended_intros):\n",
    "        paper['Introduction'] = result_intro.get(\"Introduction\", \"\")\n",
    "\n",
    "    print(\"保存处理后的数据...\")\n",
    "    save_papers(papers, output_json)\n",
    "    print(f\"处理完成，已保存到 {output_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = 'paper_metadata_1212_10k.json'  # 输入的JSON文件路径\n",
    "    output_json_file = 'papers_with_intro.json'  # 输出的JSON文件路径\n",
    "    max_workers = 10  # 最大并行线程数\n",
    "\n",
    "    main(input_json_file, output_json_file, max_workers=max_workers)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗完成，已保存到 cleaned_papers_with_intro.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 清洗“Introduction”字段中的前后多余部分\n",
    "def clean_introduction(intro_text):\n",
    "    # 提取最外层两个大括号内部的内容\n",
    "    match = re.search(r'^\"Introduction\":\\s*\"(.*?)\"$', intro_text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return intro_text  # 如果没有匹配到，返回原始内容\n",
    "\n",
    "# 处理并清洗所有论文的Introduction字段\n",
    "def clean_papers(papers):\n",
    "    for paper in papers:\n",
    "        if 'Introduction' in paper:\n",
    "            paper['Introduction'] = clean_introduction(paper['Introduction'])\n",
    "    return papers\n",
    "\n",
    "# 加载 JSON 数据\n",
    "def load_json(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 保存清洗后的 JSON 数据\n",
    "def save_json(papers, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 主函数\n",
    "def main(input_json_file, output_json_file):\n",
    "    # 加载论文数据\n",
    "    papers = load_json(input_json_file)\n",
    "    \n",
    "    # 清洗 Introduction 字段\n",
    "    cleaned_papers = clean_papers(papers)\n",
    "    \n",
    "    # 保存清洗后的数据\n",
    "    save_json(cleaned_papers, output_json_file)\n",
    "    print(f\"清洗完成，已保存到 {output_json_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = 'papers_with_intro.json'  # 输入的JSON文件路径\n",
    "    output_json_file = 'cleaned_papers_with_intro.json'  # 输出的JSON文件路径\n",
    "\n",
    "    main(input_json_file, output_json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载论文数据...\n",
      "共加载 10526 篇论文。\n",
      "Paper-710 结果:\n",
      "{'Introduction': \"\\nLarge language models (LLMs) are increasingly trained on vast and diverse internet data, which raises concerns about their ability to memorize benchmark datasets, leading to contamination of test sets. This type of contamination is particularly challenging to detect as proprietary models' pretraining data is often not publicly available. In this paper, we propose a novel procedure to detect test set contamination in language models without needing access to the pretraining data or model weights. Our method is based on the principle that without contamination, all orderings of an exchangeable benchmark dataset should have an equal probability. In contrast, a contaminated model tends to memorize the order of examples, making certain canonical orderings significantly more likely. We demonstrate the effectiveness of our approach in detecting contamination, even in challenging scenarios with smaller models, limited test sets, and rare datasets. Our results are consistent with existing evaluations and offer a reliable way to identify test set contamination in language models, including realistic evaluations using the LLaMA-2 model.\\n        \"}\n",
      "\n",
      "Paper-4089 结果:\n",
      "{'Introduction': '\\nContinual learning for generative models faces the challenge of learning new target modes with limited samples while retaining previously learned ones. This paper introduces a novel continual learning approach for generative modeling, tailored for conditional generative adversarial networks. The method involves generating samples of existing modes for replay, using a discriminator to compute mode similarity, and generating labels for the target mode based on a weighted average of similar existing modes. The model is extended by training on target data with the newly-generated labels, while employing memory replay to prevent catastrophic forgetting. Our experimental results on benchmark datasets showcase the effectiveness of our approach, demonstrating superior performance over state-of-the-art methods with fewer training samples.\\n        '}\n",
      "\n",
      "保存处理后的数据...\n",
      "处理完成，已保存到 cleaned_papers_with_introductions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 定义“Introduction”扩展任务描述模板\n",
    "task_description_template_intro = \"\"\"\n",
    "请根据以下论文摘要，扩展出一个简短的“Introduction”部分，介绍论文的背景、研究问题、方法和主要贡献。\n",
    "\n",
    "论文摘要: {abstract}\n",
    "\n",
    "输出格式：\n",
    "{{\n",
    "    \"Introduction\": \"扩展出的Introduction内容\"\n",
    "}}\n",
    "请确保生成的Introduction简洁明了，能够准确概括论文的背景、研究问题、方法和贡献。\n",
    "\"\"\"\n",
    "\n",
    "# 定义直接生成的Introduction内容\n",
    "def get_introduction_for_paper_710():\n",
    "    return {\n",
    "        \"Introduction\": \"\"\"\n",
    "Large language models (LLMs) are increasingly trained on vast and diverse internet data, which raises concerns about their ability to memorize benchmark datasets, leading to contamination of test sets. This type of contamination is particularly challenging to detect as proprietary models' pretraining data is often not publicly available. In this paper, we propose a novel procedure to detect test set contamination in language models without needing access to the pretraining data or model weights. Our method is based on the principle that without contamination, all orderings of an exchangeable benchmark dataset should have an equal probability. In contrast, a contaminated model tends to memorize the order of examples, making certain canonical orderings significantly more likely. We demonstrate the effectiveness of our approach in detecting contamination, even in challenging scenarios with smaller models, limited test sets, and rare datasets. Our results are consistent with existing evaluations and offer a reliable way to identify test set contamination in language models, including realistic evaluations using the LLaMA-2 model.\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "def get_introduction_for_paper_4089():\n",
    "    return {\n",
    "        \"Introduction\": \"\"\"\n",
    "Continual learning for generative models faces the challenge of learning new target modes with limited samples while retaining previously learned ones. This paper introduces a novel continual learning approach for generative modeling, tailored for conditional generative adversarial networks. The method involves generating samples of existing modes for replay, using a discriminator to compute mode similarity, and generating labels for the target mode based on a weighted average of similar existing modes. The model is extended by training on target data with the newly-generated labels, while employing memory replay to prevent catastrophic forgetting. Our experimental results on benchmark datasets showcase the effectiveness of our approach, demonstrating superior performance over state-of-the-art methods with fewer training samples.\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "# 加载论文数据\n",
    "def load_papers(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 保存处理后的论文数据\n",
    "def save_papers(papers, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 主函数\n",
    "def main(input_json, output_json):\n",
    "    print(\"加载论文数据...\")\n",
    "    papers = load_papers(input_json)\n",
    "    print(f\"共加载 {len(papers)} 篇论文。\")\n",
    "\n",
    "    # 提取指定索引的论文\n",
    "    target_indices = [710, 4089]  # 索引（从1开始）\n",
    "    for idx in target_indices:\n",
    "        if 1 <= idx <= len(papers):\n",
    "            paper = papers[idx - 1]  # 转为从0开始的索引\n",
    "            if idx == 710:\n",
    "                result = get_introduction_for_paper_710()\n",
    "            elif idx == 4089:\n",
    "                result = get_introduction_for_paper_4089()\n",
    "\n",
    "            paper['Introduction'] = result['Introduction']\n",
    "            print(f\"Paper-{idx} 结果:\\n{result}\\n\")\n",
    "        else:\n",
    "            print(f\"索引 {idx} 超出范围，无法处理。\")\n",
    "\n",
    "    print(\"保存处理后的数据...\")\n",
    "    save_papers(papers, output_json)\n",
    "    print(f\"处理完成，已保存到 {output_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = 'cleaned_papers_with_intro.json'  # 输入的JSON文件路径\n",
    "    output_json_file = 'cleaned_papers_with_introductions.json'  # 输出的JSON文件路径\n",
    "    main(input_json_file, output_json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper-4089:Continual learning for generative models faces the challenge of learning new target modes with limited samples while retaining previously learned ones. This paper introduces a novel continual learning approach for generative modeling, tailored for conditional generative adversarial networks. The method involves generating samples of existing modes for replay, using a discriminator to compute mode similarity, and generating labels for the target mode based on a weighted average of similar existing modes. The model is extended by training on target data with the newly-generated labels, while employing memory replay to prevent catastrophic forgetting. Our experimental results on benchmark datasets showcase the effectiveness of our approach, demonstrating superior performance over state-of-the-art methods with fewer training samples.\n",
    "\n",
    "Paper-710:Large language models (LLMs) are increasingly trained on vast and diverse internet data, which raises concerns about their ability to memorize benchmark datasets, leading to contamination of test sets. This type of contamination is particularly challenging to detect as proprietary models' pretraining data is often not publicly available. In this paper, we propose a novel procedure to detect test set contamination in language models without needing access to the pretraining data or model weights. Our method is based on the principle that without contamination, all orderings of an exchangeable benchmark dataset should have an equal probability. In contrast, a contaminated model tends to memorize the order of examples, making certain canonical orderings significantly more likely. We demonstrate the effectiveness of our approach in detecting contamination, even in challenging scenarios with smaller models, limited test sets, and rare datasets. Our results are consistent with existing evaluations and offer a reliable way to identify test set contamination in language models, including realistic evaluations using the LLaMA-2 model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
