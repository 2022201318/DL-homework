{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# 初始化 ZhipuAI 客户端\n",
    "client = ZhipuAI(api_key=\"ae569c6c31ac4c5c9aa03619d0013a89.ZbCV0v4L6OUpOwOc\")\n",
    "\n",
    "# 加载论文数据\n",
    "def load_papers(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 提取关键词并整理数据\n",
    "def extract_keywords(papers):\n",
    "    keywords_list = []\n",
    "    for paper in papers:\n",
    "        paper_id = paper.get('title')\n",
    "        keywords = paper.get('keywords', [])\n",
    "        keywords_list.append({\n",
    "            'paper_id': paper_id,\n",
    "            'keywords': keywords\n",
    "        })\n",
    "    return keywords_list\n",
    "\n",
    "# 调用大模型 API 进行聚类\n",
    "def cluster_keywords(keywords_list):\n",
    "    # 格式化为合适的任务描述\n",
    "    task_description = f\"\"\"\n",
    "请根据以下论文的关键词对论文进行聚类分析，将其按研究主题分为若干，并为每篇论文分配一个主题标签，生成“Topic”字段，标明该论文属于哪个研究主题。\n",
    "注意，你只能将他们聚为任意多类，可以尽量详细一点\n",
    "论文关键词数据：{json.dumps(keywords_list, ensure_ascii=False)}\n",
    "\n",
    "输出格式你只需要罗列类名称就行，不需要写其他的，用英文\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 调用大模型 API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"glm-4-plus\",  # 使用 glm-4-plus 模型\n",
    "            messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"你是一个专家，帮助进行论文聚类分析。\"\n",
    "            }, {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": task_description\n",
    "            }],\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "        # 提取并返回大模型的响应\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        return response_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"聚类失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 将聚类结果保存为文本文件\n",
    "def save_clustering_result(result, output_file):\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(result)  # 将结果直接保存为文本\n",
    "        print(f\"聚类结果已保存至 {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存失败: {e}\")\n",
    "\n",
    "# 主函数\n",
    "def main(input_json_file, output_txt_file):\n",
    "    print(\"加载论文数据...\")\n",
    "    papers = load_papers(input_json_file)\n",
    "    print(f\"共加载 {len(papers)} 篇论文。\")\n",
    "\n",
    "    # 提取关键词数据\n",
    "    keywords_list = extract_keywords(papers)\n",
    "    \n",
    "    # 打印提取的关键词数据\n",
    "    print(f\"提取的关键词数据：{json.dumps(keywords_list, ensure_ascii=False, indent=2)}\")\n",
    "    \n",
    "    # 调用大模型进行聚类分析\n",
    "    print(\"正在进行聚类分析...\")\n",
    "    clustering_result = cluster_keywords(keywords_list)\n",
    "    \n",
    "    if clustering_result:\n",
    "        print(\"聚类分析结果已生成，正在保存...\")\n",
    "        save_clustering_result(clustering_result, output_txt_file)\n",
    "    else:\n",
    "        print(\"聚类分析失败。\")\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = 'papers_with_keywords.json'  # 输入的JSON文件路径\n",
    "    output_txt_file = 'clustered_papers.txt'  # 输出的聚类结果文本文件路径\n",
    "    main(input_json_file, output_txt_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载文件: papers_with_tags.json\n",
      "\n",
      "未分类文章的所有tags:\n",
      "['1-Wasserstein Metric', '3D Detection', '3D Segmentation', 'AI for Climate Science', 'AI for Education', 'AIops', 'Abstraction', 'Action Model Learning', 'Action Pruning', 'Action Recognition', 'Activation Function', 'AdaGrad', 'Adaptation', 'Adaptive Asynchronous Updates', 'Adaptive Deferral Policy', 'Adaptive Learning', 'Adaptive Method', 'Adaptive Methods', 'Adaptive Sparse Approximation', 'Adaptive Stepsize', 'Aggregation', 'Algorithm', 'Algorithm Design', 'Algorithm Discovery', 'Algorithmic Inductive Bias', 'Algorithmic Interventions', 'Algorithmic Recourse', 'Algorithmic Regularization', 'Ambiguity', 'Anonymization', 'Approximate Search', 'Approximation Theory', 'Approximation-Estimation Decomposition', 'Architecture Search', 'Artificial Intelligence', 'Artificial Neural Network', 'Artificial Neural Networks', 'Asset Pricing', 'Asymmetrical Learning', 'Asynchronous Learning', 'AutoML', 'Automatic Differentiation', 'Automatic Speech Recognition', 'Automatic Story Evaluation', 'Autonomous Driving', 'Autonomous Vehicles', 'Autoregressive modeling', 'Auxiliary Functions', 'BERT', 'Backpropagation', 'Banach Space', 'Bandit Algorithms', 'Bandits', 'Bandits with Knapsack', 'Batch Learning', 'Bayesian Optimization', 'Best Arm Identification', 'Best-Arm Identification', 'Best-of-Both-Worlds', 'Bi-level Optimization', 'Bias-Variance Decomposition', 'Bin-packing', 'Binary Grids', 'Black-box Optimization', 'Blind Source Separation', 'Branch-and-Bound', 'Branch-level connectivity', 'Calcium Imaging', 'Calibration', 'Calibration Methods', 'Canonical Correlation Analysis', 'Cardinality Estimation', 'Certification for Machine Learning', 'Certified Robustness', 'Channel Adaptation', 'Chaos', 'Chaos Theory', 'Chaotic Systems', 'Character Recognition', 'Chebyshev', 'Class Imbalance', 'Classifier Calibration', 'Classifier Training', 'Client Aggregation', 'Client Sampling', 'Client-Centric', 'Climate Adaptation', 'Clipping', 'Cluster Assumption', 'Co-training', 'Cognitive Modeling', 'Cognitive Psychology', 'Collaborative Multi-Agent Reinforcement Learning', 'Combinatorial', 'Combinatorial Generalization', 'Combinatorial Multi-Armed Bandits', 'Combinatorial Optimization', 'Communication Efficiency', 'Communication efficiency', 'Comparison', 'Complementary Sparsity', 'Composed Image Retrieval', 'Composite Minimization', 'Composition', 'Compression', 'Confidence', 'Confidence Refinement', 'Conflicting Gradients', 'Conformal Prediction', 'Consensus-Based Algorithms', 'Consistency', 'Constrained Decoding', 'Constrained Machine Learning', 'Constrained Optimization', 'Constrained RL', 'Constraint Fulfillment', 'Contamination Perspective', 'Contextual Bandit', 'Contextual Bandits', 'Contextual Biasing', 'Contextual Information', 'Contextual Learning', 'Contextual Processing', 'Continuous Convolutions', 'Continuous Monitoring', 'Convergence', 'Convergence Analysis', 'Convex Optimization', 'Convex Relaxations', 'Convolution', 'Convolution-Type Smoothing', 'Convolutional neural networks', 'Cost-Efficient Framework', 'Covariance Estimation', 'Coverage Optimization', 'Coverage Path Planning', 'Critic Confidence Guided Exploration', 'Cryptographic Protocols', 'Cubic Dynamics', 'Cubic Regularization', 'Custom Learning Algorithm', 'Cycle Consistency', 'Cycle-Consistency', 'DSGD-AAU', 'Data Consistency', 'Data Depth', 'Data Encoding', 'Data Integration', 'Data Management', 'Data Programming', 'Data Security', 'Data Splits', 'Data Structures', 'Data Valuation', 'Data assimilation', 'Data-Driven Evaluation', 'Dataset', 'Deblurring', 'Decentralized Learning', 'Decentralized Optimization', 'Decentralized SGD', 'Decentralized Setting', 'Decision Boundary Stability', 'Decision Making', 'Decision-Making', 'Decision-Time Planning', 'Decomposition', 'Deep Symbolic Optimization', 'Defense', 'Dense Retrieval', 'Derandomization', 'Dialogue Generation', 'Dialogue Systems', 'Dictionary Regularization', 'Differentiable Optimization', 'Differential Privacy', 'Diffusion models', 'Diffusion-Based Planning', 'Dimensionality Reduction', 'Discrete Optimization', 'Discretization Invariant Learning', 'Discriminative Representation Learning', 'Distance Metric Learning', 'Distance Metrics', 'Distributed Learning', 'Distributed Minimization', 'Distributed Model Optimization', 'Distributed Multi-Agent', 'Distributed Optimization', 'Distributed Quantum Algorithms', 'Distributed optimization', 'Distribution Estimation', 'Distributional Reinforcement Learning', 'Distributionally Robust', 'Divergence Diagnostics', 'Divergence Theory', 'Diverse Tasks', 'Docking Path Prediction', 'Document Processing', 'Downsampling', 'Downstream RL', 'Dynamical Systems', 'Dynamics', 'Early Stopping', 'Educational Technology', 'Efficiency', 'Efficient Estimation', 'Efficient FL', 'Efficient Sampling Procedures', 'Electric Vehicles', 'Empirical Risk Minimization', 'Encoder', 'End-to-End learning', 'Energy-based Models', 'Ensemble Learning', 'Ensemble Models', 'Ensemble Projectors', 'Ensembles', 'Entity Extraction', 'Entity Linking', 'Entropy regularized OT', 'Environmental Heterogeneity', 'Environments', 'Estimation', 'Estimation Error', 'Ethical AI', 'Ethiopic Script', 'Evaluation', 'Evaluation Metrics', 'Evolution Strategies', 'Expectation-Maximization', 'Expert Models', 'Exploration', 'Extractive Summarization', 'Extragradient Method', 'Face privacy protection', 'Factor Pricing Model', 'Fast Algorithms', 'Feature Selection', 'Federated Learning', 'Federated learning', 'Feedforward Neural Networks', 'Filtering', 'Fine-Grained Structured Sparsity', 'Forecasting', 'Fourier Representation', 'Fourier Transform', 'Framework', 'Frank-Wolfe algorithm', 'Frequency Analysis', 'Friedkin-Johnson dynamics', 'Functional Modules', 'Functional Regression', 'Fusion of Experts', 'Fuzzing', 'Gap', 'Gaussian Processes', 'Generalized Eigenvalue Problem', 'Generalized Linear Models', 'Generative Modelling', 'Generative Pretrained Sequence (GPS)', 'Genetic Algorithms', 'Global Adaptation', 'Global Convergence', 'Global Optima', 'Global Optimization', 'Gradient Approximation', 'Gradient Descent', 'Gradient Descent/Ascent Algorithm', 'Gradient Free Adaptation', 'Gradient Masking', 'Gradient Minimization', 'Gradient Tracking', 'Gradient-Based Learning', 'Gradient-Free Learning', 'Graph Learning', 'Grasp Recognition', 'Grasping', 'Group Equivariant Neural Networks', 'Haptic Feedback', 'Hard Thresholding', 'Hardware Acceleration', 'Hardware-friendly', 'Hashing', 'Hausdorff Distance', 'Heavy-tailed Distributions', 'Heterogeneity', 'Heteroskedasticity', 'Hidden Markov models', 'Hierarchica transformer', 'Hierarchical Bandits', 'Hierarchical Combinatorial Optimizer', 'Hierarchical Feature Representations', 'Hierarchical Learning', 'Hierarchical Models', 'Hierarchical Planning', 'Hierarchical RL', 'Hierarchical Reinforcement Learning', 'Hierarchical Structure', 'Hierarchical Time Series', 'Hierarchical planning', 'High Order Tensor Recovery', 'High-order Methods', 'Homeomorphic Model Transformation', 'Human-Computer Interaction', 'Human-Level Performance', 'Hybrid Neural Network', 'Hybrid RL', 'Hyperparameter Optimization', 'Hyperparameter Transfer', 'Hyperparameter Tuning', 'Image Classification', 'Image Denoising', 'Image Enhancement', 'Image Processing', 'Image Quality Assessment', 'Image Restoration', 'Image Retrieval', 'Image Semantic Segmentation', 'Image Super-Resolution', 'Image classification', 'Image restoration', 'Image transformer', 'Imprecise Label Learning', 'Imputation', 'In-Distribution Generalization', 'In-context Learning', 'Incentive Compatible', 'Independent Component Analysis', 'Indexing', 'Inference Methods', 'Influence Modeling', 'Influence approximation', 'Influence-based abstraction', 'Information Extraction', 'Information Retrieval', 'Information Storage and Retrieval', 'Initialization Strategy', 'Instance-wise Similarity', 'Integer Programming', 'Interior Point Optimization', 'Interpolation', 'Interventional Data', 'Intrinsic Motivation', 'Intrinsic Reward', 'Invariance', 'Invariant Representation Learning', 'Iterative Scaling', 'Iterative Scheme', 'Jacobian-free Backpropagation', 'Kalman Filter', 'Knowledge', 'Knowledge Distillation', 'Knowledge Grounded', 'Knowledge Representation', 'Knowledge Transfer', 'LA-SSL', 'LTL', 'Label Deficiency', 'Label Hierarchy', 'Label Leakage', 'Label Propagation', 'Large Deviation Principle', 'Lasso', 'Latent Decomposition', 'Latent Representation', 'Latent Space', 'Layer-wise Learning', 'Layer-wise Pruning', 'Learning Algorithm', 'Learning Bounds', 'Learning Heuristics', 'Learning Rate', 'Learning Rate Adaptation', 'Learning Rate Decay', 'Learning Rate Schedulers', 'Learning Sparse Neural Network', 'Learning for Optimization', 'Learning from Data', 'Learning from Language', 'Learning to Optimize', 'Lexicographic Ordering', 'LiDAR', 'Library Learning', 'Lifelong Learning', 'Lightweight Optimization Framework', 'Linear Programming', 'Linear Regression', 'Linear Systems', 'Linear Transformation', 'Local Adaptation', 'Local Optimal Network', 'Local Training', 'Localization', 'Locally Adaptive Algorithms', 'Long-Form Question Answering', 'Long-term Prediction', 'Loss Function', 'Loss Gradient Weighting', 'Loss Landscape', 'Loss functions', 'Low Complexity', 'Low-Rank Adaption', 'Low-Rank Tensor Recovery', 'Low-Resource Learning', 'Low-rank Signal Reconstruction', 'Low-rank approximation', 'Low-rankness', 'MILP', 'MLOps', 'MMD-UOT', 'Machine Learning', 'Machine Learning Algorithm', 'Machine Learning in Education', 'Machine learning', 'Manipulation', 'Masked Time-Series Modeling', 'Masked image modeling', 'Mathematical Statistics', 'Matrix Recovery', 'Matrix Sensing', 'Maximum Mean Discrepancy', 'Mean Field Learning', 'Memory Metropolis', 'Memory Networks', 'Merging', 'Method of Moments', 'Metric Learning', 'Metric learning', 'Minimax Optimization', 'Minimizing Loss', 'Mirror Descent', 'Missing Data', 'Missing Modality', 'Mixed-integer Linear Programming', 'Mixture of Experts', 'Mixture-of-Experts', 'Mixup', 'Mobile object rearrangement', 'Modality Competition', 'Mode Invariance', 'Model Compression', 'Model Evaluation', 'Model Extraction', 'Model Fusion', 'Model Monitoring', 'Model Pruning', 'Model Sparsity', 'Model Transfer', 'Model-Agnostic Ensemble', 'Model-Based Learning', 'Model-based Reinforcement Learning', 'Modular Arithmetic', 'Modular RL', 'Modularity', 'Molecular Design', 'Momentum', 'Monte Carlo Approximation', 'Monte Carlo Procedures', 'Monte-Carlo Tree Search', 'Motion Prediction', 'Motion Segmentation', 'Multi task', 'Multi-Agent Reinforcement Learning', 'Multi-Agent Systems', 'Multi-Armed Bandits', 'Multi-Objective Optimization', 'Multi-Objective Reinforcement Learning', 'Multi-Sentence Prompts', 'Multi-Task Learning', 'Multi-armed Bandits', 'Multi-class Classification', 'Multi-domain Learning', 'Multi-fidelity Symbolic Optimization', 'Multi-label Learning', 'Multi-label Problems', 'Multi-modal Fusion', 'Multi-modal Learning', 'Multi-objective Optimization', 'Multi-task Learning', 'Multi-view Exploration Maximization', 'Multilingual', 'Multimodal Fusion', 'Multimodal Learning', 'Multiobjective', 'Multiresolution Analysis', 'Multitask Learning', 'Multivariate Representation Learning', 'Multivariate Time Series Prediction', 'Multiview Learning', 'NLP', 'Named Entity Recognition', 'Nanophotonic Inverse Design', 'Natural Language Generation', 'Natural Language Processing', 'Natural Language Understanding', 'Navigation', 'Nearest Neighbours Algorithm', 'Nearest neighbor search', 'Neocortex', 'Network Knowledge', 'Network Pruning', 'Network Structure', 'Neural Architecture', 'Neural Associative Memory', 'Neural Combinatorial Optimization', 'Neural Connectivity Graph', 'Neural Fields', 'Neural Information Retrieval', 'Neural Language Models', 'Neural Marked Temporal Point Processes', 'Neural Network', 'Neural Network Architecture', 'Neural Network Compression', 'Neural Network Initialization', 'Neural Networks', 'Neural Ordinary Differential Equations', 'Neural Processing', 'Neural Representation', 'Neural Response', 'Neural Scene Representations', 'Neural Set Function', 'Neural architecture search (NAS)', 'Neural delay differential equations', 'Neural graphical modeling', 'Neural networks', 'Neural operator', 'Neural substitution', 'Neuromorphic', 'Neuroscience', \"Newton's Method\", 'Newton-type Method', 'Noise', 'Noisy Label Learning', 'Non linear dynamic systems', 'Non-Convex', 'Non-Convex Optimization', 'Non-Smooth', 'Non-asymptotic analysis', 'Non-convex Optimization', 'Non-convex optimization', 'Non-parametric Models', 'Non-stationary Time Series', 'Nonconvex Functions', 'Nonconvex Nonconcave Min-Max Problems', 'Nonconvex Nonconcave Optimization', 'Nonconvex Optimization', 'Nonconvex optimization', 'Nonlinear Observer Theory', 'Nonlinear Operators', 'Nonsmooth Optimization', 'Normalizing Flows', 'Novel View Synthesis', 'OOD Detection', 'Object Detection', 'Object Discovery', 'Object-centric Learning', 'Off-policy Learning', 'Offline Optimization', 'Offline Reinforcement Learning', 'Offline-RL', 'One-Shot Learning', 'Online Decision-Making', 'Online Learning', 'Online Prediction', 'Online learning', 'Operational Efficiency', 'Operations Research', 'Operator Learning', 'Operator Norm', 'Opinion Dynamics', 'Optimal Control', 'Optimal Input Gain', 'Optimal Transport', 'Optimal transport', 'Optimisation', 'Optimisation Algorithm', 'Optimistic Gradient Method', 'Optimization', 'Optimization Algorithms', 'Optimization Theory', 'Optimization layers', 'Optimization on Manifolds', 'Oracle Policy', 'Orthogonal Decomposition', 'Out-of-Distribution Generalization', 'Out-of-distribution Generalization', 'Overfitting', 'PDEs', 'Parameter Aggregation', 'Parameter Splitting', 'Parameter-efficient Transfer Learning', 'Pareto Minimization', 'Pareto Set Learning', 'Partial Label Learning', 'Particle Decay', 'Pattern Matching', 'Pattern Recognition', 'Perceptual Embeddings', 'Performance Improvement', 'Performance Metrics', 'Periodicity', 'Personalization', 'Personalized Federated Learning', 'Personalized Models', 'Personalized Recourse', 'Personalized Slate Recommendation', 'Perturbation', 'Planning', 'Polarization', 'Policy Determination', 'Policy Evaluation', 'Policy Learning', 'Policy Network', 'Polyak Averagning', 'Positive-Unlabeled Learning', 'Post-hoc Calibration', 'Power Consumption', 'Pre-trained language models', 'Pre-training', 'Prediction', 'Prediction Intervals', 'Predictive Coding', 'Pretrained Models', 'Pretraining', 'Primal-dual algorithm', 'Principal Component Analysis', 'Prior Functions', 'Privacy', 'Privacy Attack', 'Privacy Preserving', 'Probabilistic Forecasting', 'Probabilistic Inference', 'Probabilistic Method', 'Probabilistic Predictions', 'Probabilistic Rank and Reward', 'Probabilistic Representations', 'Probability', 'Probability Estimation', 'Probability Simplex', 'Protein Complex Structure Prediction', 'Proximal Methods', 'Pruning', 'Pseudo-labeling', 'Pseudo-labels', 'QA', 'Quadratic Convergence', 'Quadratic Regression', 'Quantile Regression', 'Quantile regression', 'Quantization', 'Quantization-aware Training', 'Quantum Algorithms', 'Quantum Chemistry', 'Quantum Computing', 'Quantum Error Correction', 'Quantum Information', 'Quantum Learning Theory', 'Quantum Machine Learning', 'Quantum Mechanics', 'Quantum Monte Carlo', 'Quantum Statistical Mechanics', 'Quasi-Newton Methods', 'Quasi-Newton methods', 'Quasilinear Approximation', 'Query Optimization', 'RNN', 'RNN Model', 'Radial Basis Function', 'Random Features', 'Random Matrix Theory', 'Random Subspace', 'Random Weighting', 'Re-parameterization', 'ReLU Activation', 'Real-time', 'Recommender System', 'Recurrent Networks', 'Recurrent Neural Networks', 'Redundancy Reduction', 'Regression', 'Regret Bound', 'Regret Minimization', 'Regularization', 'Reheating Mechanism', 'Reinforcement Learning', 'Reinforcement learning', 'Relation Extraction', 'Relational Representation Learning', 'Relative Representation', 'Reliability', 'Reliable Confidence', 'Reparameterization', 'Representation Learning', 'Representation learning', 'Reproducing Kernel Hilbert Spaces', 'Reservoir Computing', 'Residual error', 'Resource-aware Algorithms', 'RetNet', 'Retrieval', 'Retrieval Augmentation', 'Retrieval Augmented Generation', 'Reward', 'Reward Shaping', 'Ride-sharing', 'Ridge Regression', 'Riemannian Geometry', 'Rigorous Analysis', 'Risk Control', 'Risk Measures', 'Risk Rewrite', 'Robotics', 'Robust Estimation', 'Robust Learning', 'Robust Optimization', 'Robustness', 'Robustness Framework', 'Rotation Equivariance', 'Rule Learning', 'SAM', 'SGD', 'SSM', 'Saddle Point Problems', 'Sample Elimination', 'Sample Reduction', 'Sampling', 'Sampling Algorithms', 'Sampling Strategies', 'Scalable Probabilistic Model', 'Scattered data', 'Scene Representations', 'Scene Understanding', 'Scheduling', 'Scientific Machine Learning', 'Search Algorithms', 'Second-Order Optimization', 'Secure Aggregation', 'Secure Machine Learning', 'Security', 'Segmentation', 'Selective Classification', 'Self-Supervised Learning', 'Self-supervised', 'Self-supervised Learning', 'Self-supervised learning', 'Self-training', 'Semantic Indexing', 'Semantic Parsing', 'Semantic Search', 'Semantic Segmentation', 'Semantic Understanding', 'Semantic representation', 'Semi-Supervised Learning', 'Semi-linear evolution', 'Semi-smooth Function', 'Semi-supervised', 'Semi-supervised Learning', 'Semi-supervised Segmentation', 'Semi-supervised learning', 'Sensor', 'Sensor Technology', 'Sensory cortex', 'Sequence Modeling', 'Sequence-to-Sequence', 'Sequential Learning', 'Sequential learning', 'Shift equivariance', 'Shift invariance', 'Shuffling', 'Sign Language Translation', 'Signal Detection', 'Signal Processing', 'Signal Reconstruction', 'Similarity-Weighted Calibration', 'Simulation', 'Single-cell', 'Skew-normal Distribution', 'Skill Transferability', 'Slot-Filling', 'Smooth Optimization', 'Social Networks', 'Software Engineering', 'Software Testing', 'Sparse Coding', 'Sparse Federated Learning', 'Sparse Learning', 'Sparse Mixture-of-Experts', 'Sparse Phase Retrieval', 'Sparse Regression', 'Sparse Representations', 'Sparse Solutions', 'Sparse System Identification', 'Sparse structure', 'Sparsity', 'Spatio-temporal Modeling', 'Spatiotemporal Modeling', 'Spectral Norm Estimation', 'Spectral Solvers', 'Speech Models', 'Speech Recognition', 'Speech Representation', 'Spiking Neural Network', 'Spiking Neural Networks', 'Split learning', 'Spurious correlations', 'Stability', 'Stable Attractors', 'State Space Model', 'Statistical Estimation', 'Statistical Estimation Theory', 'Statistical Independence', 'Statistical Learning', 'Statistical Models', 'Statistical Properties', 'Statistical Uncertainty', 'Statistics', 'Steiner Tree Packing Problem', 'Step-size Tuning', 'Stochastic Differential Equations', 'Stochastic Gradient Descent', 'Stochastic Linearization', 'Stochastic Optimization', 'Stochastic Processes', 'Streaming Algorithms', 'Streaming CCA', 'Structure discovery', 'Structure from motion', 'Structured Pruning', 'Structured Sparse Inducing Regularization', 'Subgroup Discovery', 'Submodular Maximization', 'Suboptimality', 'Subset Selection', 'Subword Segmentation', 'Super-Resolution', 'Supernet Training', 'Supervised Contrastive Learning', 'Supervised Learning', 'Surrogate Gradients', 'Surrogate Modeling', 'Surrogate-Free Optimization', 'Survival Bandit Problem', 'Sustainability', 'Symbolic Optimization', 'Symmetry Detection', 'Symmetry-Preserving Circuit', 'Synthetic Text Detection', 'System Dynamics', 'System Identification', 'Systematic Generalization', 'TSP', 'Tabular Data', 'Tabular Learning', 'Tabular SSL', 'Tail Risk', 'Task-Agnostic Pruning', 'Temperature Scaling', 'Template Networks', 'Template Optimization', 'Temporal Consistency', 'Temporal Dependence', 'Temporal Point Process', 'Temporal features', 'Temporal logic', 'Tensor Completion', 'Tensor Decomposition', 'Tensor Methods', 'Tensor Network', 'Tensor Operations', 'Tensor Rank Regularizers', 'Tensor SVD', 'Tensor networks', 'Text Classification', 'Text Detection', 'Text Evaluation', 'Text Generation', 'Text Mining', 'Text Summarization', 'Text-generating VLM', 'Text-to-Code', 'Text-to-Speech', 'Theoretic Framework', 'Time Series', 'Time Series Analysis', 'Time Series Forecasting', 'Time Super-Resolution', 'Time series forecasting', 'Time series representations', 'Time-Embeddings', 'Time-Series Classification', 'Tokenization', 'Total Variation', 'Traffic Modeling', 'Trajectory Averaging', 'Trajectory Clustering', 'Trajectory Inference', 'Transfer Learning', 'Transfer RL', 'Transfer learning', 'Transformer', 'Transformers', 'Tree Decomposition', 'Triplet Training', 'Trusted Execution Environment', 'Trustless Systems', 'Tsunami forecasting', 'Two-task Learning', 'Unbalanced Optimal Transport', 'Uncertainty', 'Uncertainty Calibration', 'Uncertainty Estimation', 'Uncertainty Modeling', 'Uncertainty Propagation', 'Uncertainty Quantification', 'Uncertainty estimation', 'Universal Optimizers', 'Unlabeled Data', 'Unnormalized Distributions', 'Unpaired Learning', 'Unsupervised Domain Adaptation', 'Unsupervised Learning', 'Unsupervised Representation Learning', 'Unsupervised learning', 'Urban Trees', 'User Experience', 'Validation', 'Variable mask ratio', 'Variance Reduction', 'Variational Inequalities', 'Variational Learning', 'Variational inference', 'Vector Neurons', 'Video Dehazing', 'Video Object Segmentation', 'Video Processing', 'Video Relighting', 'Vision Foundation Model', 'Vision-Language', 'Vision-Text', 'Visual Image Transformers', 'Visual Matching', 'Visual Place Recognition', 'Visual identity information hiding', 'Visual question answering', 'Visualization', 'Water Distribution Networks', 'Wavelet Network', 'Weak Minty Solutions', 'Weak Supervision', 'Weakly Supervised Learning', 'Weight Balancing', 'Zero-Knowledge Proofs', 'Zero-Order Optimization', 'Zero-Shot Learning', 'Zero-cost Proxies', 'Zero-order Optimization', 'Zero-shot Generalization', 'Zero-shot Learning', 'Zero-shot learning', 'Zeroth-Order Optimization', 'cognitive neuroscience', 'fMRI', 'generalization', 'sparse recovery']\n",
      "各类别文章数量统计： {'ML': 3345, 'AI': 2329, 'DL': 4379, 'Unclassified': 473}\n",
      "分类后的文件已保存为: classified_papers.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 定义类别和关键词\n",
    "categories = {\n",
    "  \"AI\": [\n",
    "    \"AI Alignment\",\n",
    "    \"AI Safety\",\n",
    "    \"Application in Healthcare\",\n",
    "    \"Automated Reasoning\", \n",
    "    \"Bioinformatics\",\n",
    "    \"Biomedical Knowledge Graph Construction\",\n",
    "    \"Brain-Computer Interfaces\",\n",
    "    \"Chess\",\n",
    "    \"Clinical Decision-Making\",\n",
    "    \"Clinical Notes\",\n",
    "    \"Code Generation\",\n",
    "    \"Communication\",\n",
    "    \"Computer Graphics\",\n",
    "    \"Computer Vision\",\n",
    "    \"Control Theory\",\n",
    "    \"Drug Discovery\",\n",
    "    \"Earth System Modeling\", \n",
    "    \"Edge Computing\",\n",
    "    \"EEG\",\n",
    "    \"EHR\",\n",
    "    \"Electronic Health Records\",\n",
    "    \"Explainable AI\",\n",
    "    \"Human-Agent Collaboration\",\n",
    "    \"Human Feedback\",\n",
    "    \"Human Perception\",\n",
    "    \"Human Vision\",\n",
    "    \"Language Model\",\n",
    "    \"Large Language Models\",\n",
    "    \"Machine Translation\",\n",
    "    \"Material Science\",\n",
    "    \"Mathematical Reasoning\",\n",
    "    \"Computational Linguistics\",\n",
    "    \"Computational Neuroscience\",\n",
    "    \"Computational Physics\",\n",
    "    \"Dynamic Scene Understanding\",\n",
    "    \"Learning from Demonstration\",\n",
    "    \"Learning from Textual Feedback\",\n",
    "    \"Emergent Communication\",\n",
    "    \"Game Theory\",\n",
    "    \"Information Theory\",\n",
    "    \"Chemistry\",\n",
    "    \"Chemical Reaction\",\n",
    "    \"Deformation\",\n",
    "    \"Dehazing\",\n",
    "    \"Detection\",\n",
    "    \"Differentiable Physics\",\n",
    "    \"Elasticity\",\n",
    "    \"Electricity\",\n",
    "    \"Event Camera\",\n",
    "    \"Fluid Dynamics\",\n",
    "    \"Human Activity Recognition\",\n",
    "    \"Imitation Learning\",\n",
    "    \"Interpretability\",\n",
    "    \"Instance-Level Explanation\",\n",
    "    \"Inpainting\",\n",
    "    \"Input-Output Maps\"\n",
    "  ],\n",
    "  \"DL\": [\n",
    "    \"Attention Mechanism\",\n",
    "    \"Autoencoder\",\n",
    "    \"CLIP\",\n",
    "    \"Concept Bottleneck Models\", \n",
    "    \"Deep Learning\",\n",
    "    \"Deep Reinforcement Learning\",\n",
    "    \"Deformable Convolution\",\n",
    "    \"Diagnosing Transformers\",\n",
    "    \"Diffusion Models\",\n",
    "    \"Efficient Deep Learning\",\n",
    "    \"Efficient Inference\",\n",
    "    \"Efficient Training\",\n",
    "    \"Embedding Learning\",\n",
    "    \"Equivariant Neural Networks\",\n",
    "    \"Foundation Models\",\n",
    "    \"Generative Pretraining\",\n",
    "    \"Geometric Deep Learning\",\n",
    "    \"Graph Neural Networks\",\n",
    "    \"Implicit Neural Representations\",\n",
    "    \"Memory-Augmented Neural Networks\",\n",
    "    \"Neural Architecture Search\",\n",
    "    \"Audio Processing\",\n",
    "    \"Generative Models\",\n",
    "    \"High-Resolution Image Synthesis\",\n",
    "    \"In-Context Learning\",\n",
    "    \"In-Context Pretraining\",\n",
    "    \"Latent Dynamics\",\n",
    "    \"Heterogeneous Graph Learning\",\n",
    "    \"Feature Learning\",\n",
    "    \"Discrete Representation Learning\",\n",
    "    \"Conditional Generative Modeling\",\n",
    "    \"Contrastive Learning\",\n",
    "    \"Cross-Modal Learning\",\n",
    "    \"Catastrophic Forgetting\",\n",
    "    \"Chain-of-Thought\",\n",
    "    \"Collaborative Filtering\",\n",
    "    \"Compositional Generalization\",\n",
    "    \"Curriculum Learning\",\n",
    "    \"Data Augmentation\",\n",
    "    \"Data Distillation\",\n",
    "    \"Dataset Distillation\",\n",
    "    \"Denoising\",\n",
    "    \"Depth Completion\",\n",
    "    \"Depth Estimation\",\n",
    "    \"Disentanglement\",\n",
    "    \"Few-shot Learning\",\n",
    "    \"Fine-tuning\",\n",
    "    \"Information Bottleneck\",\n",
    "    \"Long-tailed Learning\"\n",
    "  ],\n",
    "  \"ML\": [\n",
    "    \"Active Learning\",\n",
    "    \"Adversarial Attacks\",\n",
    "    \"Adversarial Defense\",\n",
    "    \"Adversarial Training\",\n",
    "    \"Anomaly Detection\",\n",
    "    \"Average Reward Markov Decision Processes\",\n",
    "    \"Bayesian Deep Learning\",\n",
    "    \"Bayesian Inference\",\n",
    "    \"Benchmark\",\n",
    "    \"Biased Learning\",\n",
    "    \"Bilevel Optimization\",\n",
    "    \"Bird Migration\",\n",
    "    \"Black-box Attack\",\n",
    "    \"Black-box Defense\",\n",
    "    \"Brownian Dynamics\",\n",
    "    \"Causal Discovery\",\n",
    "    \"Causal Inference\",\n",
    "    \"Causal Representation Learning\",\n",
    "    \"Circuit Complexity\",\n",
    "    \"Classification\",\n",
    "    \"Clustering\",\n",
    "    \"Compressed Sensing\",\n",
    "    \"Compressive Learning\",\n",
    "    \"Computational Complexity\",\n",
    "    \"Computational Efficiency\",\n",
    "    \"Computational Geometry\",\n",
    "    \"Continual Learning\",\n",
    "    \"Cooperative Multi-Agent Reinforcement Learning\",\n",
    "    \"Counterfactual Generation\",\n",
    "    \"Covariate Shift\",\n",
    "    \"Credit Assignment\",\n",
    "    \"Data Curation\",\n",
    "    \"Data Efficiency\",\n",
    "    \"Data Heterogeneity\",\n",
    "    \"Data Poisoning\",\n",
    "    \"Data Privacy\",\n",
    "    \"Density Estimation\",\n",
    "    \"Dimension Reduction\",\n",
    "    \"Distribution Shift\",\n",
    "    \"Domain Adaptation\",\n",
    "    \"Energy Efficiency\",\n",
    "    \"Episodic Memory\",\n",
    "    \"Error Analysis\",\n",
    "    \"Evolutionary Algorithms\",\n",
    "    \"Fairness\",\n",
    "    \"Fitness Landscape Analysis\",\n",
    "    \"Foveated Vision\",\n",
    "    \"Function Approximation\",\n",
    "    \"Generalization\",\n",
    "    \"Geometry\",\n",
    "    \"Group Robustness\",\n",
    "    \"Heterogeneous Learning\",\n",
    "    \"Heterophily\",\n",
    "    \"High-Dimensional Data\",\n",
    "    \"Hyperbolic Space\",\n",
    "    \"In-distribution Generalization\",\n",
    "    \"Incremental Learning\",\n",
    "    \"Kernel Methods\",\n",
    "    \"Koopman Theory\",\n",
    "    \"Learning Theory\",\n",
    "    \"Lipschitz Continuity\",\n",
    "    \"Manifold Learning\",\n",
    "    \"Markov Decision Processes\",\n",
    "    \"Matrix Completion\",\n",
    "    \"Meta Learning\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "def classify_article(article):\n",
    "    \"\"\"根据文章的标签分类\"\"\"\n",
    "    article_tags = article.get(\"tags\", [])\n",
    "    \n",
    "    # 如果没有标签，记录为未分类\n",
    "    if not article_tags:\n",
    "        return \"Unclassified\"\n",
    "    \n",
    "    # 先按标签在tags列表中的顺序，选择类别\n",
    "    for tag in article_tags:\n",
    "        for category, category_keywords in categories.items():\n",
    "            if tag in category_keywords:\n",
    "                return category\n",
    "\n",
    "    # 如果没有匹配的标签，记录为未分类\n",
    "    return \"Unclassified\"  # 默认分类为\"未分类\"（如果没有匹配）\n",
    "\n",
    "def classify_articles_from_json(json_data):\n",
    "    \"\"\"根据给定的 JSON 数据对所有论文进行分类，并输出未分类论文的tags\"\"\"\n",
    "    classified_articles = []\n",
    "    unclassified_tags = set()  # 用于收集所有未分类文章的tags\n",
    "    \n",
    "    for article in json_data:\n",
    "        category = classify_article(article)\n",
    "        article[\"category\"] = category\n",
    "        classified_articles.append(article)\n",
    "        \n",
    "        # 如果论文被标记为未分类，记录其tags\n",
    "        if category == \"Unclassified\":\n",
    "            article_tags = article.get(\"tags\", [])\n",
    "            unclassified_tags.update(article_tags)\n",
    "    \n",
    "    # 打印所有未分类文章的tags\n",
    "    if unclassified_tags:\n",
    "        print(\"\\n未分类文章的所有tags:\")\n",
    "        print(sorted(list(unclassified_tags)))\n",
    "    \n",
    "    return classified_articles\n",
    "\n",
    "def count_categories(classified_articles):\n",
    "    \"\"\"统计每个类别的文章数量\"\"\"\n",
    "    category_counts = {\"ML\": 0, \"AI\": 0, \"DL\": 0, \"Unclassified\": 0}\n",
    "    \n",
    "    for article in classified_articles:\n",
    "        category = article.get(\"category\", \"Unclassified\")\n",
    "        category_counts[category] += 1\n",
    "    \n",
    "    return category_counts\n",
    "\n",
    "# 步骤 1: 读取 JSON 文件\n",
    "def load_json_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# 步骤 2: 保存分类后的 JSON 数据\n",
    "def save_json_file(filename, data):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 主流程\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载 JSON 文件（假设文件名为 papers.json）\n",
    "    input_filename = \"papers_with_tags.json\"  # 输入文件名\n",
    "    output_filename = \"classified_papers.json\"  # 输出文件名\n",
    "    \n",
    "    # 步骤 1: 读取论文数据\n",
    "    try:\n",
    "        papers_data = load_json_file(input_filename)\n",
    "        print(f\"成功加载文件: {input_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件 {input_filename} 不存在!\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 步骤 2: 分类所有论文\n",
    "    classified_papers = classify_articles_from_json(papers_data)\n",
    "    \n",
    "    # 步骤 3: 统计各类别文章数量\n",
    "    category_counts = count_categories(classified_papers)\n",
    "    print(\"各类别文章数量统计：\", category_counts)\n",
    "    \n",
    "    # 步骤 4: 保存分类后的数据\n",
    "    save_json_file(output_filename, classified_papers)\n",
    "    print(f\"分类后的文件已保存为: {output_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# 初始化 ZhipuAI 客户端\n",
    "client = ZhipuAI(api_key=\"ad670367ab3640d78468ddc62b7ca3f2.GhKvhDzmSOe3QN9O\")\n",
    "\n",
    "# 设置日志记录\n",
    "def setup_logger(log_file='logs111.txt'):\n",
    "    logger = logging.getLogger('paper_classification')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "# 加载论文数据\n",
    "def load_papers(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 保存处理后的论文数据\n",
    "def save_papers(papers, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 记录模型的回复日志\n",
    "def log_model_response(idx, category):\n",
    "    with open(\"model_response_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"Paper-{idx} categorized as: {category}\\n\")\n",
    "\n",
    "# 记录错误日志\n",
    "def log_error(idx, error_message, model_response=None):\n",
    "    with open(\"error_log.txt\", \"a\", encoding=\"utf-8\") as error_file:\n",
    "        error_file.write(f\"Error for Paper-{idx}: {error_message}\\n\")\n",
    "        if model_response:\n",
    "            error_file.write(f\"Model Response: {model_response}\\n\\n\")\n",
    "\n",
    "# 调用大模型 API 进行分类\n",
    "def classify_paper(keywords, idx, logger):\n",
    "    task_description = f\"\"\"\n",
    "请根据以下论文的关键词将论文分类为 AI (人工智能)、DL (深度学习)、ML (机器学习) 其中之一。\n",
    "\n",
    "论文关键词：{json.dumps(keywords, ensure_ascii=False)}\n",
    "\n",
    "输出格式：AI, DL, ML,注意，只能聚为一类，不能多聚，而且输出不能加括号，只能是AI, DL, ML这样的缩写\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"glm-4-flash\",  # 使用 glm-4-plus 模型\n",
    "            messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"你是一个专家，帮助对论文进行分类。\"\n",
    "            }, {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": task_description\n",
    "            }],\n",
    "            temperature=0.1      )\n",
    "\n",
    "        # 提取并记录分类结果\n",
    "        category = response.choices[0].message.content.strip()\n",
    "        log_model_response(idx, category)\n",
    "        logger.info(f\"Paper-{idx} classified as: {category}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # 记录错误\n",
    "        log_error(idx, str(e))\n",
    "        logger.error(f\"Error classifying Paper-{idx}: {str(e)}\")\n",
    "\n",
    "# 并行处理论文分类\n",
    "def classify_papers_in_parallel(papers, logger, max_workers=10):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        for idx, paper in enumerate(papers):\n",
    "            keywords = paper.get('keywords', [])\n",
    "            future = executor.submit(classify_paper, keywords, idx, logger)\n",
    "            futures.append(future)\n",
    "        \n",
    "        # 等待所有任务完成\n",
    "        for future in futures:\n",
    "            future.result()  # 阻塞，直到所有任务完成\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置日志\n",
    "    logger = setup_logger()\n",
    "\n",
    "    # 加载论文数据\n",
    "    input_file = \"papers_with_keywords.json\"\n",
    "    papers = load_papers(input_file)\n",
    "    \n",
    "    # 分类论文\n",
    "    classify_papers_in_parallel(papers, logger)\n",
    "\n",
    "    # 保存处理后的数据（可以选用）\n",
    "    output_file = \"classified_papers.json\"\n",
    "    save_papers(papers, output_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
